{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T16:31:21.384486Z","iopub.status.busy":"2023-08-23T16:31:21.384200Z","iopub.status.idle":"2023-08-23T16:31:26.280717Z","shell.execute_reply":"2023-08-23T16:31:26.279239Z","shell.execute_reply.started":"2023-08-23T16:31:21.384460Z"},"trusted":true},"outputs":[],"source":["##########################Load Libraries  ####################################\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","\n","import random \n","\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","\n","from torchinfo import summary\n","import pandas as pd\n","import os\n","\n","from tqdm import trange\n","import inspect\n","import time\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","\n","from myUtils import *\n","from plottingUtils import *"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#hyperparameters\n","\n","data_dir = \".\\datasets\\PJM_power\"\n","fname = \"COMED_hourly.csv\"\n","\n","sample_len = 360\n","step = 1\n","target_len = 120\n","batch_size = 64\n","steps_in_day = 24\n","\n","HID_DIM = 128\n","RNN_LAYERS = 4\n","LIN_LAYERS = 2\n","DROPOUT = 0.5\n","N_SIN_TERMS = 16\n","N_PARAMS = 2 + 3*N_SIN_TERMS\n","\n","desired_features = None"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T16:31:26.283778Z","iopub.status.busy":"2023-08-23T16:31:26.283074Z","iopub.status.idle":"2023-08-23T16:31:26.378834Z","shell.execute_reply":"2023-08-23T16:31:26.377332Z","shell.execute_reply.started":"2023-08-23T16:31:26.283736Z"},"trusted":true},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Using {} device\".format(device))\n","print(torch.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def apply_vals(vals, seq):\n","    '''\n","    vals: [batch size, n_features, n_params]\n","    \n","    '''\n","    batch_size = vals.shape[0]\n","    n_features = vals.shape[1]\n","    vals = vals.unsqueeze(3)\n","    #print(\"vals\", vals.shape, vals.device)\n","    seq = seq.unsqueeze(0).unsqueeze(1).repeat(batch_size, n_features, 1).float()\n","    #print(\"seq\", seq.shape, seq.device)\n","    #print(\"x0\", vals[:,:,0].shape)\n","    #print(\"a\", vals[:,:,2::2].shape)\n","    x =  vals[:,:, 3::3] + torch.matmul(vals[:,:, 4::3], seq.unsqueeze(2))\n","    #print(\"x\", x.shape, x.device)\n","    #print(\"a\", vals[:,:,2::3].shape)\n","    out = vals[:,:,0] + vals[:,:,1] * seq + (vals[:,:, 2::3] * torch.sin(x)).sum(2)\n","    #print(\"out\", out.shape, out.device)\n","    return out.permute(0, 2, 1).contiguous()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T16:31:27.885343Z","iopub.status.busy":"2023-08-23T16:31:27.884341Z","iopub.status.idle":"2023-08-23T16:31:27.897215Z","shell.execute_reply":"2023-08-23T16:31:27.896517Z","shell.execute_reply.started":"2023-08-23T16:31:27.885309Z"},"trusted":true},"outputs":[],"source":["class Fourier(nn.Module):\n","    def __init__(self, n_features, n_params, device, hid_dim = 64, rnn_layers = 2, lin_layers=1 ,dropout=0.5):\n","        super().__init__()\n","\n","        self.hid_dim = hid_dim\n","        self.n_layers = rnn_layers\n","        self.device = device\n","\n","        self.rnn = nn.GRU(\n","            input_size=n_features,\n","            hidden_size=hid_dim,\n","            num_layers=rnn_layers,\n","            dropout=dropout,\n","            batch_first=True,\n","        )\n","\n","        # create fc\n","        self.fc = nn.Sequential()\n","        for i in range(lin_layers):\n","            self.fc.add_module(f\"lin{i}\", nn.Linear(hid_dim * rnn_layers, hid_dim * rnn_layers))\n","            self.fc.add_module(f\"relu{i}\", nn.ReLU())\n","        self.fc.add_module(f\"lin{lin_layers}\", nn.Linear(hid_dim * rnn_layers, n_params * n_features))\n","\n","\n","    def forward(self, src):\n","        # src = [batch size, src len, n features]\n","\n","        batch_size = src.shape[0]\n","        n_features = src.shape[2]\n","\n","        _, hidden = self.rnn(src)\n","\n","        # hidden = [n layers, batch size, hid dim]\n","        hidden = hidden.permute(1, 0, 2).reshape(batch_size, -1).contiguous()\n","        # hidden = [batch size, n layers * hid dim]\n","        output = self.fc(hidden)\n","        # output = [batch size, n params * n features]\n","        return output.reshape(batch_size, n_features, -1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T16:31:34.654505Z","iopub.status.busy":"2023-08-23T16:31:34.654119Z","iopub.status.idle":"2023-08-23T16:31:34.673751Z","shell.execute_reply":"2023-08-23T16:31:34.672816Z","shell.execute_reply.started":"2023-08-23T16:31:34.654467Z"},"trusted":true},"outputs":[],"source":["# model fitting\n","\n","def train(\n","    dataloader,\n","    model,\n","    loss_fn,\n","    optimizer,\n","    iter_count=None,\n","    visibility=True,\n","):\n","    \"\"\"\n","    dataloader: iterable\n","    model: model to train\n","    loss_fn: loss function\n","    optimizer: used optimizer\n","    iter_count: number of iterations, if None then dataloader length\n","    desired_features: list of features to be used in loss calculation, if None then all features\n","    teacher_forcing_ratio: probability to use teacher forcing\n","    visibility: boolean, if True then show progress bar\n","    \"\"\"\n","    assert not (\n","        inspect.isgenerator(dataloader) and iter_count is None\n","    ), \"generator must have specified size\"\n","    if iter_count is None:\n","        iter_count = len(dataloader.dataset)\n","\n","    data_iterator = iter(dataloader)\n","    model.train()\n","    average_loss = 0\n","\n","    r = trange(iter_count) if visibility else range(iter_count)\n","\n","    for _ in r:\n","        x, y = next(data_iterator)\n","        x, y = x.to(device), y.to(device)\n","        # Compute prediction error\n","\n","        pred = model(x)\n","        value = apply_vals(pred, torch.arange(y.shape[1]).to(device))\n","        \n","        loss = loss_fn(value, y)\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        average_loss += loss.item()\n","\n","    average_loss /= iter_count\n","\n","    return average_loss\n","\n","\n","def eval(\n","    dataloader, \n","    model, \n","    loss_fn, \n","    iter_count=None, \n","    visibility=True\n","):\n","    \"\"\"\n","    dataloader: iterable\n","    model: model to train\n","    loss_fn: loss function\n","    iter_count: number of iterations, if None then dataloader length\n","    desired_features: list of features to be used in loss calculation\n","    visibility: boolean, if True then show progress bar\n","    \"\"\"\n","    if iter_count is None:\n","        iter_count = len(dataloader.dataset)\n","    data_iterator = iter(dataloader)\n","    model.eval()\n","    test_loss = 0\n","    with torch.no_grad():\n","        r = trange(iter_count) if visibility else range(iter_count)\n","        for _ in r:\n","            x, y = next(data_iterator)\n","            x, y = x.to(device), y.to(device)\n","\n","            pred = model(x)\n","            value = apply_vals(pred, torch.arange(y.shape[1]).to(device))\n","\n","            test_loss += loss_fn(value, y).item()\n","\n","    test_loss /= iter_count\n","\n","    return test_loss\n","\n","\n","def fit_model(\n","    model,\n","    train_dataloader,\n","    val_dataloader,\n","    loss_fn,\n","    optimizer,\n","    scheduler,\n","    epochs=5,\n","    train_iter_count=None,\n","    val_iter_count=None,\n","    visibility = 0,\n","    save_model = False\n","):\n","    '''\n","    model: model to train\n","    train_dataloader: iterable\n","    val_dataloader: iterable\n","    loss_fn: loss function\n","    optimizer: used optimizer\n","    epochs: number of epochs\n","    train_iter_count: number of training iterations\n","    val_iter_count: number of validation iterations\n","    desired_features: list of features to be used in loss calculation\n","    teacher_forcing_ratio: probability to use teacher forcing\n","    visibility: 0 - no progress bar, 1 - progress bar for entire training, 2 - progress bar for each epoch\n","    save_model: boolean, if True then save model with lowest validation loss\n","    '''\n","    history = {\n","        \"train\": {\"loss\": []},\n","        \"val\": {\"loss\": []},\n","    }\n","    total_time_start = time.time()\n","    r = trange(epochs) if visibility == 1 else range(epochs)\n","\n","    min_val_loss = np.inf\n","\n","    for t in r:\n","        if visibility == 2:\n","            print(f\"Epoch {t+1}\\n-------------------------------\")\n","            print(\"Test\")\n","        train_loss = train(\n","            train_dataloader,\n","            model,\n","            loss_fn=loss_fn,\n","            optimizer=optimizer,\n","            iter_count=train_iter_count,\n","            visibility=(visibility == 2),\n","        )\n","        if visibility == 2:\n","            print(\"Eval\")\n","        val_loss = eval(\n","            val_dataloader,\n","            model,\n","            loss_fn=loss_fn,\n","            iter_count=val_iter_count,\n","            visibility=(visibility == 2),\n","        )\n","\n","        scheduler.step(val_loss)\n","\n","        if min_val_loss > val_loss and save_model:\n","            min_val_loss = val_loss\n","            torch.save(model, \"model.pth\")\n","        if visibility == 2:\n","            print(f\"Train Error: Avg loss: {train_loss:.4f} \")\n","            print(f\"Validation Error: Avg loss: {val_loss:.4f} \\n\")\n","        if visibility == 1:\n","            r.set_postfix({\"Avg\": f\"{val_loss:.4f}\", \"Min\": f\"{min_val_loss:.4f}\"})\n","        history[\"train\"][\"loss\"].append(train_loss)\n","        history[\"val\"][\"loss\"].append(val_loss)\n","\n","    total_time_end = time.time()\n","    total_duration = total_time_end - total_time_start\n","    \n","    average_duration = total_duration / epochs\n","    if visibility != 0:\n","        print(f\"Total Duration: {print_duration(total_duration)}\")\n","        print(f\"Average Duration: {print_duration(average_duration)}\")\n","        print(f\"Min Validation Loss: {min_val_loss:.4f}\")\n","\n","    \n","    return history"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T16:31:26.398127Z","iopub.status.busy":"2023-08-23T16:31:26.397553Z","iopub.status.idle":"2023-08-23T16:31:26.701135Z","shell.execute_reply":"2023-08-23T16:31:26.699820Z","shell.execute_reply.started":"2023-08-23T16:31:26.398090Z"},"trusted":true},"outputs":[],"source":["# preprocessing\n","\n","df = extract_dataframe(data_dir, fname)\n","#df = add_features(df, steps_in_day=steps_in_day)\n","\n","header, float_data = extract_data(df)\n","normalized_data, mean, std = normalize_data(float_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["timesteps = len(float_data)\n","print(f'{timesteps} timesteps')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T16:31:26.785460Z","iopub.status.busy":"2023-08-23T16:31:26.783807Z","iopub.status.idle":"2023-08-23T16:31:26.796556Z","shell.execute_reply":"2023-08-23T16:31:26.795248Z","shell.execute_reply.started":"2023-08-23T16:31:26.785424Z"},"trusted":true},"outputs":[],"source":["# generators\n","\n","train_max_index = int(timesteps * 0.7)\n","\n","train_generator = floating_window_batch_generator(\n","    normalized_data,\n","    sample_len=sample_len,\n","    target_len=target_len,\n","    min_index=0,\n","    max_index=train_max_index,\n","    shuffle=True,\n","    step=step,\n","    batch_size=batch_size,\n","    \n",")\n","\n","val_generator = floating_window_batch_generator(\n","    normalized_data,\n","    sample_len=sample_len,\n","    target_len=target_len,\n","    min_index=train_max_index+1,\n","    max_index=timesteps,\n","    shuffle=True,\n","    step=step,\n","    batch_size=batch_size\n",")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T16:31:26.862561Z","iopub.status.busy":"2023-08-23T16:31:26.861667Z","iopub.status.idle":"2023-08-23T16:31:27.859434Z","shell.execute_reply":"2023-08-23T16:31:27.858291Z","shell.execute_reply.started":"2023-08-23T16:31:26.862526Z"},"trusted":true},"outputs":[],"source":["samples, targets = next(train_generator)\n","for feature in range(samples.shape[-1]):\n","    print(header[feature])\n","    plot_samples(samples, targets, feature, figsize=(15,1))\n","\n","#assert False"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def init_weights(m):\n","    if isinstance(m, nn.Linear):\n","        torch.nn.init.xavier_uniform_(m.weight)\n","        m.bias.data.fill_(0.01)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T16:31:27.899095Z","iopub.status.busy":"2023-08-23T16:31:27.898327Z","iopub.status.idle":"2023-08-23T16:31:34.163614Z","shell.execute_reply":"2023-08-23T16:31:34.162505Z","shell.execute_reply.started":"2023-08-23T16:31:27.899057Z"},"trusted":true},"outputs":[],"source":["# instantiate model\n","\n","N_FEATURES = float_data.shape[1]\n","\n","model = Fourier(\n","    n_features=N_FEATURES,\n","    n_params=N_PARAMS,\n","    device=device,\n","    hid_dim=HID_DIM,\n","    rnn_layers=RNN_LAYERS,\n","    lin_layers=LIN_LAYERS,\n","    dropout=DROPOUT,\n",").to(device)\n","# init weights\n","\n","model.apply(init_weights)\n","\n","# model = Iterative(N_SAMPLES, HID_DIM, N_LAYERS, DROPOUT).to(device)\n","print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T16:31:34.165598Z","iopub.status.busy":"2023-08-23T16:31:34.165225Z","iopub.status.idle":"2023-08-23T16:31:34.642863Z","shell.execute_reply":"2023-08-23T16:31:34.641624Z","shell.execute_reply.started":"2023-08-23T16:31:34.165563Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["summary(\n","    model,\n","    input_size=(10, sample_len, N_FEATURES),\n","    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\", \"kernel_size\"],\n","    col_width=15,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T16:31:34.645302Z","iopub.status.busy":"2023-08-23T16:31:34.644873Z","iopub.status.idle":"2023-08-23T16:31:34.652190Z","shell.execute_reply":"2023-08-23T16:31:34.650975Z","shell.execute_reply.started":"2023-08-23T16:31:34.645244Z"},"trusted":true},"outputs":[],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T16:31:34.689736Z","iopub.status.busy":"2023-08-23T16:31:34.689365Z","iopub.status.idle":"2023-08-23T16:37:32.601916Z","shell.execute_reply":"2023-08-23T16:37:32.600921Z","shell.execute_reply.started":"2023-08-23T16:31:34.689701Z"},"trusted":true},"outputs":[],"source":["# Fit model\n","\n","loss_fn = nn.MSELoss()\n","learning_rate = 1e-2\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10)\n","\n","history = fit_model(\n","    model,\n","    train_dataloader=train_generator,\n","    train_iter_count=100,\n","    val_dataloader=val_generator,\n","    val_iter_count=50,\n","    loss_fn=loss_fn,\n","    optimizer=optimizer,\n","    scheduler=scheduler,\n","    epochs=100,\n","    save_model=True,\n","    visibility=1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T16:37:32.604390Z","iopub.status.busy":"2023-08-23T16:37:32.603586Z","iopub.status.idle":"2023-08-23T16:37:32.913593Z","shell.execute_reply":"2023-08-23T16:37:32.912665Z","shell.execute_reply.started":"2023-08-23T16:37:32.604352Z"},"trusted":true},"outputs":[],"source":["plot_history(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T16:37:32.915689Z","iopub.status.busy":"2023-08-23T16:37:32.914857Z","iopub.status.idle":"2023-08-23T16:37:32.925089Z","shell.execute_reply":"2023-08-23T16:37:32.923885Z","shell.execute_reply.started":"2023-08-23T16:37:32.915649Z"},"trusted":true},"outputs":[],"source":["\n","\n","def make_predictions(model, samples, len):\n","    with torch.no_grad():\n","        values = model(samples.to(device))\n","        #print(values[0])\n","        output = apply_vals(values, torch.arange(len).to(device))\n","    return output\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T16:37:32.929039Z","iopub.status.busy":"2023-08-23T16:37:32.928143Z","iopub.status.idle":"2023-08-23T16:37:45.792084Z","shell.execute_reply":"2023-08-23T16:37:45.791176Z","shell.execute_reply.started":"2023-08-23T16:37:32.929011Z"},"trusted":true},"outputs":[],"source":["model = torch.load(\"model.pth\")\n","\n","\n","for _ in range(10):\n","    model.eval()\n","    samples, targets = next(val_generator)\n","    output = make_predictions(model, samples, targets.shape[1])\n","    print(output.shape)\n","\n","    plot_predictions(header, samples, targets, output, mean, std)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
